{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS4020 Example - Predicting whether student passes or fails a course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The following cell has imports needed throughout the entire example. The documentation for the following libraries are publically available on their respective websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#specifying configurations for our graphs\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "\n",
    "pd.readcsv(filename, headerRow) -> reads the data and inputs it into a **DataFrame (refer to pandas documentation)**\n",
    "\n",
    "data.dropna() -> drops all rows that have missing or invalid data in the form of **NaN (refer to python documentation)**\n",
    "\n",
    "data.shape -> returns (row count, column count)\n",
    "\n",
    "data.columns -> returns a list of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('student-mat.csv', header=0)\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the data\n",
    "\n",
    "data['index'] -> returns all the rows in column index\n",
    "data['index'].value_counts -> returns a count for each value appearing in the data. \n",
    "\n",
    "i.e. the value 10 appears 56 times in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['G3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our classifiers\n",
    "\n",
    "As we saw in the data the final grade of each student is out of 20 so we need to classify what grade is considered a passing grade and what grade is considered a failing grade.\n",
    "\n",
    "In our exampl, we will use the standard 50% passing threshold and anything below this will be considered a fail.\n",
    "\n",
    "Using this we can transform our data by labeling all grades below 10 to False and the remaining should be labeled as True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['G3'].values[data['G3'] < 10] = False\n",
    "data['G3'].values[data['G3'] >= 10] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing our classifiers using graphs\n",
    "\n",
    "We can visualize the amount of passing and failing students using graphs.\n",
    "\n",
    "We can infer that twice as many students have passed the course than failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='G3', data=data, palette='hls')\n",
    "plt.show()\n",
    "plt.savefig('count_plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study time is defined as:\n",
    "\n",
    "1 = < 2 hours per week\n",
    "\n",
    "2 = 2 to 5 hours per week\n",
    "\n",
    "3 = 5 to 10 hours per week\n",
    "\n",
    "4 = > 10 hours per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(data.studytime,data.G3).plot(kind='bar')\n",
    "plt.title('Study Time vs Pass or Fail')\n",
    "plt.xlabel('Study Time')\n",
    "plt.ylabel('Frequency of pass/fail')\n",
    "plt.savefig('purchase_fre_job')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing our classifiers using numbers\n",
    "\n",
    "Using numbers we can see that there are almost twice as many students who passed the course than failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_fail = len(data[data['G3'] == 0])\n",
    "count_pass = len(data[data['G3'] == 1])\n",
    "pct_of_pass = count_pass/(count_pass+count_fail)\n",
    "print(\"percentage of failing students is\", pct_of_pass*100)\n",
    "pct_of_pass = count_fail/(count_pass+count_fail)\n",
    "print(\"percentage of passing is\", pct_of_pass*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing our classifiers using the mean of all features\n",
    "\n",
    "We can visualize our classifiers based on the mean of all continuous. (categorical data will not be shown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('G3').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Categorical Columns into Boolean Columns\n",
    "\n",
    "A lot of functions in sklearn are not compatible with categorical data so it can be helpful to expand a categorical columns into several boolean columns.\n",
    "\n",
    "i.e. If school is a categorical variable with two possible categories (GP or MS) we can create two columns called school_GP and school_MS and use boolean values indicating whether a student attends MS or GP.\n",
    "\n",
    "In the case, a student attends the school MS the columns would look like :\n",
    "\n",
    "**school_MS school_GP**\n",
    "\n",
    "**TRUE FALSE**\n",
    "\n",
    "The next few cells accomplish this and creates a list of the new set of columns and updates the existing dataset with these columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars=['school','sex','address','famsize','Pstatus','schoolsup','famsup','paid','activities','nursery', 'higher', 'internet', 'romantic', 'Mjob', 'Fjob', 'reason', 'guardian']\n",
    "for var in cat_vars:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "    data1=data.join(cat_list)\n",
    "    data=data1\n",
    "cat_vars=['school','sex','address','famsize','Pstatus','schoolsup','famsup','paid','activities','nursery', 'higher', 'internet', 'romantic', 'Mjob', 'Fjob', 'reason', 'guardian']\n",
    "data_vars=data.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=data[to_keep]\n",
    "(data_final.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may uncommon the code below to normalize the data by using a oversampling function provided by imblearn.\n",
    "\n",
    "This function equalizes the training dataset with an even distribution of passing and failing students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_final.loc[:, data_final.columns != 'G3']\n",
    "y = data_final.loc[:, data_final.columns == 'G3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "os_data_X = X_train\n",
    "os_data_y = y_train\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# os = SMOTE(random_state=0)\n",
    "# columns = X_train.columns\n",
    "\n",
    "# os_data_X,os_data_y=os.fit_sample(X_train, y_train.values.ravel())\n",
    "# os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "# os_data_y= pd.DataFrame(data=os_data_y,columns=['G3'])\n",
    "\n",
    "# # we can Check the numbers of our data\n",
    "# print(\"length of oversampled data is \",len(os_data_X))\n",
    "# print(\"Number of students failed in oversampled data\",len(os_data_y[os_data_y['G3']==0]))\n",
    "# print(\"Number of students passed\",len(os_data_y[os_data_y['G3']==1]))\n",
    "# print(\"Proportion of students failed data in oversampled data is \",len(os_data_y[os_data_y['G3']==0])/len(os_data_X))\n",
    "# print(\"Proportion of students passed data in oversampled data is \",len(os_data_y[os_data_y['G3']==1])/len(os_data_X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "\n",
    "We can recursively remove features by continuously removing features and analyzing whether there is any improvement in the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_vars=data_final.columns.values.tolist()\n",
    "y=['G3']\n",
    "X=[i for i in data_final_vars if i not in y]\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then filter our data and only pick out the features selected by the RFE function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "cols = list(compress(X, rfe.support_))\n",
    "X=os_data_X[cols]\n",
    "y=os_data_y['G3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model\n",
    "\n",
    "We can then build the model from the training set and summarize our findings and remove features accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict whether a student passed or failed in the test dataset using our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the confusion matrix and see how well our model performs and how often a false positive or a false negative occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can validate our model using the precision, accuracy and recall values. (In this case our model seems to do well but that could also be due to overfitting and heavy bias due to a small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will notice the accuracy is very high, this is likely due to the very small subset of data used which causes our model to overfit. \n",
    "\n",
    "A few things we can do is gather more data, increase our oversampling and analyze every feature used in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
